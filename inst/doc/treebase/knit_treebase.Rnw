\documentclass[authoryear, preprint]{elsarticle}
%\documentclass[authoryear, 5p]{elsarticle}

%\VignetteIndexEntry{treebase}
%% Redefines the elsarticle footer
\makeatletter
\def\ps@pprintTitle{%
 \let\@oddhead\@empty
 \let\@evenhead\@empty
 \def\@oddfoot{\it \hfill\today}%
 \let\@evenfoot\@oddfoot}
\makeatother

\bibliographystyle{elsarticle-harv}
\biboptions{sort&compress}
\usepackage{graphicx}
\usepackage[pdftex, colorlinks]{hyperref}
\usepackage{amsmath, amsfonts}  % extended mathematics
\usepackage{booktabs} % book-quality tables
\textwidth 6.75in
\oddsidemargin -0.15in
\evensidemargin -0.15in
\textheight 9in
\topmargin -0.5in
\newcommand{\ud}{\mathrm{d}}


%% Looks like a comment but it isn't! This is setting the default behavior for the Sweave chunk options,  
% \SweaveOpts{fig=TRUE, cache=FALSE, message=FALSE, warning=FALSE, tidy=FALSE, dev='pdf'}
                   

\begin{document}
\begin{frontmatter}
  \title{An introduction to the \texttt{treebase} Package}
  \author[davis]{Carl Boettiger\corref{cor1}}
  \ead{cboettig@ucdavis.edu}
  \author[stats]{Duncan Temple Lang}
  \cortext[cor1]{Corresponding author.}
  \address[davis]{Center for Population Biology, University of California, Davis, United States}
  \address[stats]{Department of Statistics, University of California, Davis, United States}

  \begin{abstract}
  \begin{enumerate}
  \item TreeBASE is an important and rapidly growing repository of phylogenetic data.  The R statistical environment has become a primary tool for the applied phylogenetic analyses that use this kind of data for across a range of questions, from comparative evolution to community ecology to conservation planning.  
  \item We have developed \texttt{treebase}, an open-source package (freely available from\\ \href{http://cran.r-project.org/web/packages/treebase}{http://cran.r-project.org/web/packages/treebase}) for the R environment.  \texttt{treebase} provides simplified and programmatic access to phylogenetic data that provides a bridge between the repository and the rapidly growing ecosystem of R packages for phylogenetics with which many researchers are already familiar.  
  \item We illustrate how such programmatic access has important ramifications for research, including making scientific results easier to reproduce and update,
  \item and also facilitate exploratory analysis, longitudinal studies and meta-analyses at a scale that would hither-to be daunting for most research teams.  
  \end{enumerate}

  \end{abstract}

  \begin{keyword}
   R  \sep software \sep API \sep TreeBASE \sep tools \sep e-science
   \end{keyword}
 \end{frontmatter}

\section{Introduction}
Applications that use phylogenetic information as part of their analyses 
are becoming increasingly central to both evolutionary and ecological research. 
The explosion of genomic data, followed by methodological advances for 
inferring phylogenies from this molecular information have helped spur this increase. 
% . . . 


The R statistical environment has become a dominant platform for researchers using this phylogenetic data 
to address a rapidly expanding set of questions in ecological and evolutionary processes.
While the task of inferring phylogenies from sequence data remains dominated by dedicated compiled software such as MrBayes~\citep{Huelsenbeck2001b}, BEAST~\citep{Drummond2007}, RAXML~\citep{Stamatakis2006},
the research methods that make use of the phylogenies they infer are largely based in R. 
To distinguish between the processes of inferring the phylogeny and these applications,
We will refer collectively to this area of research which uses phylogenetic relationships as input data as applied phylogenetics.  


These methods include tasks such as ancestral state reconstruction~\citep{Paradis2004, Butler2004}, 
diversification analysis~\citep{Paradis2004, Rabosky2006b, Harmon2008, FitzJohn2009, FitzJohn2010, Goldberg2011, Stadler2011}, 
quantifying the rate and tempo of trait evolution~\citep{Butler2004, Paradis2004, Harmon2008, Hipp2010, Revell2011, Eastman2011}, 
identifying evolutionary influences and proxies for community ecology~\citet{Webb2008, Kembel2010}, 
performing phyloclimatic modelling~\citep{Warren2008, Evans2009b}, 
and simulation of speciation and character evolution~\citep{Harmon2008, Stadler2011a, Boettiger2012}, 
as well as various manipulation and visualization of phylogenetic data~\citet{Paradis2004, Schliep2010, Jombart2010, Revell2011}.  

While several programs exist for applied phylogenetic methods in languages such as 
Java~\citep{Maddison2011}, MATLAB~\citep{Blomberg2003} and Python~\citep{Sukumaran2010} as well as through online servers~\citep{Martins2004}, 
today, none offer the same breadth in methods or number of users, 
a trend reinforced by the growing number of workshops teaching applied phylogenetic methods.   
We mention this not to dismiss the value added by these other languages, 
but to highlight the obvious benefit users and developers of these methods could derive from programmatic access to the common underlying data structure for these analyses -- the phylogenetic trees themselves.  

TreeBASE (\href{http://treebase.org}{http://treebase.org})
is an online repository of phylogenetic data (e.g. trees of species, populations, or genes) 
that have been published in a peer-reviewed academic journal, book, thesis or conference proceedings~\citep{Sanderson1994b, Morell1996}. 
The database can be searched through an online interface which 
allows users to find a phylogenetic tree from a particular publication, author or taxa of interest.  
TreeBASE provides an application programming interface (API) 
that lets computer applications make queries to the database.  
Our \texttt{treebase} package uses this API to create a direct link between this data and the R language, 
making it easier for users and developers to take advantage of this data.  
In this paper, we provide several examples to illustrate what such programmatic access could mean for applied phylogenetics research.  



\section{Examples \& Results}

<<libs, echo=FALSE>>=
library(treebase)
@


The basic functions of the TreeBASE API allow search queries of the phylogenetic data in the repository
(using the phylo-ws interface) and the metadata of publications associated with the phylogenies (using the OAI-MPH interface).
These interfaces are well-documented on the TreeBASE website.
The \texttt{treebase} package allows these queries to be made directly from R,
just as a user would make them from the browser.
Because the queries can be implemented programmatically in R,
a user can construct more complicated filters than permitted by the web interface, 
and can maintain a record of the queries they used to collect their data as an R script.  
The ability to script this data-gathering step of research can go a long way to reducing errors
and ensuring that an analysis can be replicated later, by the author or other groups~\citep{Peng2011a}.  

\subsection{Basic Queries}
Any of the basic queries available on the web interface can now be made directly from R,
including downloading and importing the phylogeny into the R interface.  
For instance, one can search for phylogenies containing dolphin taxa,
or all phylogenies submitted by a given author
<<basicQueries, eval=FALSE>>=
search_treebase("Delphinus", by="taxon")
search_treebase("Huelsenbeck", by="author")
@
These functions loads the matching phylogenies into R, ready for analysis.  
The package documentation provides many examples of possible queries. 
The \verb|search_treebase| function is the heart of the \texttt{treebase} package.  
While basic queries such as these seem simple,
we present several use-cases of how this programmatic access can be leveraged to allow rapid exploration of phylogenetic data
that opens doors to faster and easier verification of results and also new kinds of analysis and new scales of analysis. 

To illustrate this potential, we first introduce the second core function, \verb|search_metadata|, which provides metadata about the resources available in the TreeBASE repository.  Using programmatic access to this metadata and standard analysis tools available in R, we can quickly paint an up-to-the-minute picture of the data currently available TreeBASE.  We will then return our \verb|search_treebase| function to illustrate several ways we can take advantage of the programmatic access to the data.  

\subsection{Quantifying TreeBASE}
The \texttt{treebase} package provides access to the metadata of all publications containing trees
deposited in TreeBASE using a seperate API for metadata.  
This can help the user discover phylogenies of interest
and also allows the user to perform statistical analyses
on the data deposition itself, which could identify trends or biases in the phylogenetics literature.  


While the metadata can search for all entries before or after a given date.  If no argument is given, it will return the entire avialable database.  
<<getmetadata>>=
metadata <- search_metadata() 
@
The returned object is a list, in which each element is an entry with bibliographic information corresponding to a published study that has deposited data in TreeBASE.  Asking for the list length tells us there are \Sexpr{length(metadata)} published studies currently in the database.  

R provides a rich statistical environment in which we can extract and visualize the data we have just obtained. 
For instance, we may wish to obtain a list of all the dates of publication \& names of the journals (publishers) that have submitted data:
<<journals>>=
dates <- sapply(metadata, `[[`, "date")
pub <- sapply(metadata, `[[`, "publisher")
@
which we organize into a table,
<<head_pub, comment=NA>>=
pub_table <- sort(table(as.character(pub)), decreasing=TRUE)
@

Many journals have only a few submissions, so we will group them together as ``Other'':  
<<top_journals>>=
top_contributors <- names(head(pub_table,10))
pub[!(pub %in% top_contributors)] <- "Other"
@

We can then look at the distribution of publication years for phylogenies deposited in TreeBASE,
color coding by publisher in Fig~\ref{fig:1}.
It is encouraging to see that no single journal dominates the submissions, 
and taxa-specific publications and more broad-scope journals share the top ten spots. 
It will be interesting to watch these trends as more journals extend mandatory archiving requirements
over the coming years.  

\setkeys{Gin}{width=\linewidth}
\begin{figure}
\begin{center}
<<dates, fig.width=16, fig.height=6, cache=FALSE>>=
meta <- data.frame(publisher = as.character(pub), dates = dates)
require(ggplot2)
ggplot(meta) + geom_bar(aes(dates, fill = publisher))
@
\caption{Histogram of publication dates by year, with the code required to generate the figure.}\label{fig:1}
\end{center}
\end{figure}

In addition to this information about the publications, we can obtain metadata about the phylogenies themselves from the \verb|search_treebase| function.  While this information is always returned by the query, we can request \verb|only_metadata| for a quick look at the data matching any search

<<only_metadata>>=
genetrees <- search_treebase( "'Gene Tree'", by='kind.tree', only_metadata=TRUE )
@
This query returns just the metadata for the \Sexpr{length(genetrees)} gene trees in the database, including the study identifier number of where they were published, the number of taxa in the tree, a quality score, (if available), kind of tree (gene tree, species tree, or barcode tree) and whether the phylogeny represents a single or consensus type.  



For certain applications a user may wish to download all the available phylogenies from TreeBASE. Using the \verb|cache_treebase| function allows a user to download a local copy of all trees.  Because direct database dumps are not available, this function has intentional delays to avoid overtaxing the TreeBASE servers, and should be allowed a full day to run.  
<<bulidcache, eval=FALSE>>=
treebase <- cache_treebase()
@

Once run, the cache is saved compactly in memory where it can be easily and quickly restored.  For convience, the \texttt{treebase} package comes with a copy already cached, which can be loaded into memory.
<<loadcachedtreebase>>=
data(treebase)
@

It is possible to use this function with the \verb|only_metadata| option as well, which should run in minutes and return the metadata we just mentioned for all available phylogenies.  
<<tree_metadata_cache>>=
tree_metadata <- cache_treebase(only_metadata=TRUE)
@

Having access to both the metadata from the studies and from the phylogenies in R lets us quickly combine these data sources in interesting ways.  For instance, with a few commands we can visualize how the number of taxa on submitted phylogenies has increasing over time, Figure~\ref{fig:2}.  
% How fast is tree size growing as a function of publication date?  
% Color code by journal?   by author?

%first_author <- sapply(metadata, `[[`, 'creator') 
%author_table <- sort(table(as.character(first_author)), decreasing=TRUE)
%top_contributors <- names(head(author_table,10))
%first_author[!(first_author %in% top_contributors)] <- "Other"

\begin{figure}
<<treestats>>=
<<taxagrowth, fig.width=16, fig.height=6>>=
studyid <- sapply(tree_metadata,`[[`, 'S.id')
sid <- sapply(metadata, `[[`, 'identifier')
sid <- gsub(".*TB2:S(\\d*)", "\\1", sid)
matches <- sapply(sid, match, studyid)
Ntaxa <- sapply(matches, function(i)  tree_metadata[[i]]$ntax)
Ntaxa[sapply(Ntaxa, is.null)] <- NA
taxa <- data.frame(Ntaxa=as.numeric(unlist(Ntaxa)), meta)
ggplot(taxa, aes(dates, Ntaxa)) + 
  geom_point(position = 'jitter', alpha = .8) + 
  scale_y_log10() + stat_smooth(aes(group = 1))
@
\caption{Combining the metadata avialable from publications and from phylogenies themselves,
we can visualize the growth in taxa on published phylogenies. 
Note that the maximum size tree deposited each year is growing far faster than the average number.}\label{fig:2}
\end{figure}
The promise of this exponential growth in the sizes of available phylogenies,
with some trees representing~\Sexpr{max(taxa$Ntaxa, na.rm=TRUE)} taxa motivates
the more and more ambitious inference methods being developed
which require large trees to have adequate signal~\citep{Boettiger2012, FitzJohn2009}.
It will be interesting to see how long into the future this trend is maintained.
These visualizations help identify research trends and can also help identify potential data sets for analyses. 
In this next section we highlight a few ways in which programatic access can be leveraged for various research objectives.  


\subsection{Reproducible research \& education}
Reproducible research has become a topic of increasing concern in recent years~\citep{Schwab2000, Gentleman2004, Peng2011b}.  
Access to data and executable scripts that reproduce the results presented 
are two central elements of this process which are addressed by the \texttt{treebase} package.   


Imagine reading the recent phylogenetics paper,~\citet{Derryberry2011}. 
The paper analyzes speciation models on a phylogeny of bird taxa to identify if the rate of speciation shows
a substantial shift among any of the groups, using the R package~\texttt{laser}~\citep{Rabosky2006b}.  
We recall that more recent methods for identifying these rate shifts were presented in~\citet{Stadler2011},
and would like to see if the results presented hold up under the newer approach.  
The \texttt{treebase} package can help us do this with minimal effort.  
Further, because the process can be entirely scripted in R, from accessing the data to performing the analyses,
it can be easily replicated \& extended to additional datasets or methods.  


\subsubsection*{Obtaining the tree}
By drawing on the rich data manipulation tools available in R (and thus familiar to the large R phylogenetics community),
the \texttt{treebase} package allows us to construct richer queries than are possible through TreeBASE alone.
We begin our search by asking for a phylogenies by one of the paper's authors:  

<<findderryberry>>= 
derryberry_results <- search_treebase("Derryberry", "author")
@

This shows several results. 
We would like the phylogeny appearing in \emph{Evolution} in 2011.
Each phylogeny includes a TreeBASE study id number, stored in the ``S.id'' element, 
which we use to look up the metadata for each paper.
<<filter>>=
ids <- lapply(derryberry_results, `[[`, "S.id")
meta <- lapply(ids, metadata)
@

We can then look through the metadata to find the study matching our description.  
<<matchderryberry>>=
i <- which( sapply(meta, function(x) x$publisher == "Evolution" && x$date=="2011") )
derryberry <- derryberry_results[[i]]
@
This is simply one possible path to identify the correct study, certainly this query could be constructed in other ways, including direct access by the study identifer.   

%<<loadderryberry, echo=FALSE>>=
%# connection may fail on first try, so instead of evaluating this, just load cached copy
%data(derryberry)
%@

Having successfuly imported the phylogenetic tree corresponding to this study,
we can quickly replicate their analysis of which diversification process best fits the data.
Different diversification models make different assumptions about the rate of speciation, extinction,
and how these rates may be changing over time.  
The authors consider eight different models, implemented in the \texttt{laser}~package \citep{Rabosky2006b}.
This code fits each of the eight models to that data:
<<RR, tidy=FALSE>>=
require(laser)
tt <- branching.times(derryberry)
models <- list(             yule = pureBirth(tt),  
                     birth_death = bd(tt),     
                     yule.2.rate = yule2rate(tt),
      linear.diversity.dependent = DDL(tt),    
 exponential.diversity.dependent = DDX(tt),
         varying.speciation_rate = fitSPVAR(tt),  
         varying.extinction_rate = fitEXVAR(tt),  
                    varying_both = fitBOTHVAR(tt)  
              )
@
Each of the model estimate includes an AIC score indicating the goodness of fit, 
penalized by model complexity (lower scores indicate better fits)
We ask R to tell us which model has the lowest AIC score,
<<extract_aic>>=
aics <- sapply(models, function(x) x$aic)
best_fit <- names(models[which.min(aics)])
@ 
and confirm the result presented in~\citet{Derryberry2011}, that the \texttt{\Sexpr{best_fit}} model is the best fit to the data.  


In this fast-moving field, new methods often become available within the time-frame 
that another manuscript is submitted by its authors and the time at which if first appears in print.  
For instance, the more sophisticated methods available in the more recent package, \texttt{TreePar}, 
introduced in~\citet{Stadler2011} were not used in this study.

<<TreeSimError, echo=FALSE>>=
# Locale settings to be safe
Sys.setlocale(locale="C") -> locale
rm(list="locale") # clean up
@

We load the new method and format the data as its manual instructs us
<<treepar, include=FALSE>>=
require(TreePar)
x<-sort(getx(derryberry), decreasing=TRUE)
@

The best-fit model in the laser analysis was a yule (net diversification rate) models with two seperate rates.  
We can ask \texttt{TreePar} to see if a model with more rate shifts is favored over this single shift,
a question that was not possible to address using the tools provided in~\texttt{laser}. 
The previous analysis also considers a birth-death model that allowed speciation and extinction rates to 
be estimated seperately, but did not allow for a shift in the rate of such a model.  
Here we consider models that have up to 4 different rates in yule models,
<<treepar_yule, include=FALSE>>=
yule_models <- bd.shifts.optim(x, sampling = c(1,1,1,1), grid = 5, start = 0, end = 60, yule = TRUE)[[2]]
@
(The syntax in \texttt{TreePar} is slightly cumbersome, the [[2]] indicates 
We also want to compare the performance of models which allow up to four shifts and also 
estimate extinction and speciation seperately:
<<treepar_birthdeath, include=FALSE>>=
birth_death_models <- bd.shifts.optim(x, sampling = c(1,1,1,1), grid = 5, start = 0, end = 60, yule = FALSE)[[2]]
@
The models output by these functions are ordered by increasing number of shifts.  
We can select the best-fitting model by AIC score,
<<aic_yule>>=
yule_aic <- sapply(yule_models, function(pars) 2 * (length(pars) - 1) + 2 * pars[1] )
birth_death_aic <- sapply(birth_death_models, function(pars) 2 * (length(pars) - 1) + 2 * pars[1] )
which.min(c(yule_aic, birth_death_aic))
@
which confirms that the original Yule 2-rate %\Sexpr{#which.min(aic)}-rate 
model is still the best choice based on AIC score.  

This kind of verification of results and validation against alternate methods
will not occur regularly as long as the time required to do so is not negligible.  
While this kind of analysis already enjoys the benefits of scripted software implementations 
of the methods being employed, access to the actual data has become the rate-limiting step.  

By being able to access the phylogenentic data programmatically, as shown in this example,
replicating an analysis can become a matter of minutes instead of hours or days.  


\subsection{A self-updating meta-analysis?}
Large scale comparative analyses that seek to characterize evolutionary patterns across many phylogenies increasingly common in phylogenetic methods~\citep[\emph{e.g}][]{McPeek2007, Phillimore2008, McPeek2008, Quental2010, Davies2011a}.  
Often referred to by their authors as meta-analyses,
these approaches have focused on re-analyzing phylogenetic trees collected from many different earlier publications.  
This is a more direct approach than the traditional concept of meta-analysis
where statistical results from earlier studies are weighted by their sample size
without actually repeating the statistical analyses of those papers.

and avoids some of the statistical challenges inherent in summarizing results that may differ in methodology.  While potentially valuable, these researchers have often gone through heroic efforts simply to assemble these data sets from the literature.  As described in \citet{McPeek2007}, (emphasis added)
\begin{quote}
One data set was based on 163 published species-level molecular phylogenies of arthropods, chordates, and mollusks. [\dots] A PDF format file of each article was obtained, and a digital snapshot of the figure was taken in Adobe Acrobat 7.0. This image was transferred to a PowerPoint (Microsoft) file and printed on a laser printer. The phylogenies included in this study are listed in the appendix. \emph{All branch lengths were measured by hand from these  printed sheets using dial calipers.}
\end{quote}
While several digital tools are available to make these kind of measurements without the calipers~\citep[\emph{e.g.}][]{Laubach2007},
it is immensely easier and less error-prone to pull properly formatted phylogenies from the database for this purpose.   

%By building such meta-analyses around the \texttt{treebase} package, 
%one can not only take advantage of the existing data with substantially less effort, 
%but also provide a script that can be automatically updated as more phylogenies are deposited in the TreeBASE repository. 

%Researchers may focus their meta-analysis on particular taxa~\citep{Phillimore2008}, 
%leaving us to wonder if the conclusions hold in other groups.  
%Other studies may use a single empirical tree accompanied by a a collection of simulated phylogenies~\citet{Cusimano2010}.  
%Some already turn to TreeBASE to provide a more extensive collection of phylogenies~\citep{Davies2011a}.  


The central question in these studies has been whether or not phylogenies show a changing rates of evolution. 
%This question is important for several reasons.  %% ADD STUFF & CITE 
A standard test of this is the $\gamma$ statistic of~\citet{Pybus2000} which tests the null hypothesis that the rates of speciation and extinction are constant. 

In this section we illustrate how we can perform a similar meta-analysis to the studies such as~\citet[\emph{e.g}][]{McPeek2007, Phillimore2008, McPeek2008,Quental2010, Davies2011a} across a much larger set of phylogenies and with just a few lines of R code.   Because the entire analysis, including the access of the data, is scriptable, we could simply recompile this document some time in the future and see how the pattern we find has changed with the addition of more data.  

\subsubsection*{Testing for constant speciation and extinction rates across all of treebase}
The \texttt{treebase} package provides a compressed cache of the phylogenies available in treebase.  This cache can be automatically updated with the \verb|cache_treebase| function,
<<meta_harvest, eval=FALSE>>=
treebase <- cache_treebase()
@
which may require a day or so to complete, and will save a file in the working directory named with ``treebase'' and the date obtained.  For convience, we can load the cached copy distributed with the \texttt{treebase} package:

<<cachedcopy>>=
data(treebase)
@

% future versions should be able to update only those records that have changed or been added.  Should be easy script of metadata + search by study id.  

We will only be able to use those phylogenies that include branch length data.  We drop those that do not from the data set, 
<<branchlengthfilter>>=
      have <- have_branchlength(treebase)
      branchlengths <- treebase[have]

@

Like most comparative methods, this analysis will require ultrametric trees (branch lengths proportional to time, rather than to mutational steps). As most of these phylogenies are calibrated with branch length proportional to mutational step, we must time-calibrate each of them first.  
%This function is just an elementary example to illustrate the process of time-calibrating a tree;
%more sophisticated methods could be chosen instead.  
<<timetree, cache=TRUE>>=
timetree <- function(tree){
    try( chronoMPL(multi2di(tree)) )
}
tt <- drop_nontrees(sapply(branchlengths, timetree))
@


Applying this test to all of the currently available trees with branchlengths in TreeBASE,
<<gamma, echo=TRUE>>=
# gamma statistic
gammas <- sapply(tt,  gammaStat)
# associated p-value
p_gammas <- 2 * (1 - pnorm(abs(gammas)))
non_const <- sum(p_gammas < 0.025, na.rm=TRUE)/length(gammas)
@
we find that \Sexpr{round(non_const, 2)*100}\% of the trees can reject the constant-rates model at the 95\% confidence level. 
Because \texttt{treebase} makes it possible to perform this analysis entirely by scripts using the latest treebase data, 
it is not only easier to perform this analysis but also to update it to reflect the latest data. 
For instance, this paper is written using R's Sweave tool, where the results and figures are generated on the fly as the paper is compiled.  
Consequently the analyses presented here can be updated to reflect the latest information in TreeBASE by the click of a button.  


%\subsection{\texttt{treebase} for methods developers}
%One advantage a common programming platform has brought 


\section{Conclusion}

The recent advent of mandatory data archiving in many of the major journals publishing phylognetics-based research~\citep[\emph{e.g.}][]{Fairbairn2010, Piwowar2011, Whitlock2010}, is a particularly promising development that should continue to fuel trend of submissions seen in Fig.~\ref{fig:1}.  Faced with such a rapidly growing supply, programmatic access to data becomes not only increasingly powerful but an increasingly necessary way to ensure we can see the forest for the trees.   

 \section{Acknowledgements}
 CB wishes to thank the TreeBASE developer team for building and supporting the repository, and all contributers to TreeBASE.
 CB is supported by a Computational Sciences Graduate Fellowship from the Department of Energy under grant number DE-FG02-97ER25308.   
 \section*{ }%bibliography
% \bibliography{/home/cboettig/Documents/Mendeley/bib/library}
  \bibliography{treebase}
<<save, echo=FALSE>>=
save(list=ls(), file="knit_treebase.rda")
@


\end{document}


