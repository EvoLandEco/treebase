% Treebase: An R package for discovery, access and manipulation of online phylogenies 

1.  The TreeBASE portal is an important and rapidly growing repository of
    phylogenetic data. The R statistical environment has also become a
    primary tool for applied phylogenetic analyses that use this kind
    of data across a range of questions, from comparative evolution
    to community ecology to conservation planning.

2.  We have developed `treebase`, an open-source  (freely
    available from
    [http://cran.r-project.org/web/packages/treebase](http://cran.r-project.org/web/packages/treebase))
    for the R programming environment, providing simplified, programmatic and
    interactive access to phylogenetic data in the TreeBASE repository.

3.  We illustrate how this package creates a bridge between the
    repository and the rapidly growing ecosystem of R packages for
    phylogenetics that can reduce barriers to discovery and integration
    across phylogenetic research.

4.  We show how the `treebase` package can be used to facilitate replication
    of previous studies and testing of methods and hypotheses across
    a large sample of phylogenies, which may help make such 
    important practices more common.


#### Keywords 

R, software, API, TreeBASE, database, e-science

Introduction
============


Applications that use phylogenetic information as part of their analyses
are becoming increasingly central to both evolutionary and ecological
research. The exponential growth in genetic sequence data available for
all forms of life has driven rapid advances in the methods that can
infer the phylogenetic relationships and divergence times across
different taxa [@huelsenbeck2001b; @stamatakis2006; @drummond2007].
Once again the product of one field has become the raw data of the next. 
Unfortunately, while the discipline of
bioinformatics has emerged to help harness and curate the wealth of
genetic data with cutting edge computer science, statistics, and
internet technology, its counterpart in evolutionary informatics remains
“scattered, poorly documented, and in formats that impede discovery and
integration” [@parr2011a]. Our goal when developing the `treebase`
package is to provide steps to reduce these challenges through programmatic and
interactive access between the repositories that store this data and the
software tools commonly used to analyze them.  The tools provided in the
`treebase` package can make discovery and analysis easier and more replicable, 
and facilitate scaling analyses across an ever growing repository of potential 
phylogenetic data.  


In this paper we  focus on applications which use rather than
generate phylogenetic data. Such approaches stand to benefit substantially from
this programmatic and interactive access to TreeBASE.  
The R statistical environment [@rteam2012] has
become a dominant platform for researchers using phylogenetic data to
address a rapidly expanding set of questions in ecological and
evolutionary processes. These methods include, but are not limited to,
ancestral state reconstruction [@paradis2004; @butler2004], 
diversification analysis [@paradis2004; @rabosky2006b; @harmon2008],
identifying trait dependent speciation and extinction rates, [@fitzjohn2010; @goldberg2011; @stadler2011],
quantifying the rate and tempo of trait evolution
[@butler2004; @harmon2008; @eastman2011],
identifying evolutionary influences and proxies for community ecology
[@webb2008; @kembel2010], 
connecting phylogeny data to climate patterns [@warren2008; @evans2009b], 
and simulation of speciation and character evolution 
[@harmon2008; @stadler2011a; @boettiger2012], as
well as various manipulations and visualizations of phylogenetic data
[@paradis2004; @schliep2010; @jombart2010; @revell2011]. A more
comprehensive list of R packages by analysis type is available on the
phylogenetics taskview,
[http://cran.r-project.org/web/views/Phylogenetics.html](http://cran.r-project.org/web/views/Phylogenetics.html).
A few programs for applied phylogenetic methods are written for environments outside the R language,
incuding Java [@maddison2011], MATLAB [@blomberg2003] and Python [@sukumaran2010] and online interfaces
[@martins2004].


TreeBASE ([http://treebase.org](http://treebase.org)) is an online
repository of phylogenetic data (e.g. trees of species, populations, or
genes) that have been published in a peer-reviewed academic journal,
book, thesis or conference proceedings
[@sanderson1994b; @morell1996]. The database can be searched through
an online interface which allows users to find a phylogenetic tree from
a particular publication, author or taxa of interest. TreeBASE provides
an application programming interface (API) that lets computer
applications make queries to the database. Our `treebase` package uses
this API to create a direct link between this data and the R language.
This has several immediate and important benefits:

1. *Data discovery.*  Users can leverage the rich hihger-level programming environment 
provided by the R language to better identify data sets appropriate for
their research by constructing queries for datasets that match appropriate metadata
requirements.  

2. *Programmatic data access.* Many tasks that are theoretically made possible
by the creation of the TreeBASE repository are not pursued because they would 
be too laborious for an exploratory analysis.  The ability to use loops to 
automatically download and perform a systematic analysis using the rich set of 
tools available in R opens up new avenues for research.

3. *Automatic updating*.  The TreeBASE repository is expanding rapidly.  The 
scriptable nature of analyses run in with our `treebase` package means that 
a study can be rerun on the latest version of the repository without additional
effort.  


Basic queries
--------------

``` {r libs, echo=FALSE}
    library(treebase)
    library(ggplot2)
````

The basic functions of the TreeBASE API allow search queries through two
separate interfaces. The `OAI-PMH` interface provides the metadata
associated with the publications from which the phylogenies have been
taken, while the `Phylo-WS` interface provides information and access to
the phylogenetic data itself. These interfaces are well-documented on
the TreeBASE website. The `treebase` package allows these queries to be
made directly from R, just as a user would make them from the browser.
Because the queries can be implemented programmatically in R, a user can
construct more complicated filters than permitted by the web interface,
and can maintain a record of the queries they used to collect their data
as an R script. The ability to script this data-gathering step of
research can go a long way to reducing errors and ensuring that an
analysis can be replicated later, by the author or other groups [@peng2011a].

Any of the queries available on the web interface can now be made
directly from R, including downloading and importing the phylogeny into
the R interface. For instance, one can search for phylogenies containing
dolphin taxa, "Delphinus," or all phylogenies submitted by a given
author, "Huelsenbeck",

``` {r basicQueries, eval=FALSE }
    search_treebase("Delphinus", by="taxon")
    search_treebase("Huelsenbeck", by="author")
````

This function loads the matching phylogenies into R, ready for analysis.
The package documentation provides many examples of possible queries.
The `search_treebase` function is the heart of the `treebase` package.
Table 1 lists each of the types of queries available through the
`search_treebase` function.  This list can also be found in the function 
documentation, `?search_treebase`.  


  search "by="     description
  ---------------  -----------------------------------------------------
  abstract         search terms in the publication abstract
  author           match authors in the publication
  subject          Matches in the subject terms
  doi              The unique object identifier for the publication 
  ncbi             NCBI identifier number for the taxon
  kind.tree        Kind of tree (Gene tree, species tree, barcode tree)  
  type.tree        Type of tree (Consensus or Single)
  ntax             Number of taxa in the matrix
  quality          A quality score for the tree, if it has been rated.  
  study            Match words in the title of the study or publication
  taxon            Taxon scientific name 
  id.study         TreeBASE study ID
  id.tree          TreeBASE's unique tree identifier (Tr.id)
  id.taxon         Taxon identifier number from TreeBase 
  tree             The title for the tree

Table: Queries available in `search_treebase`



Data discovery in TreeBASE
==========================

The `treebase` package provides access to the metadata of all
publications containing trees deposited in TreeBASE using a separate API
built on the OAI-PMH protocol, an international web standard such data.
This can help the user discover phylogenies of interest and also allows
the user to perform statistical analyses on the data deposition itself,
which could identify trends or biases in the phylogenetics literature.

This publication metadata is accessed by `search_metadata` function, 
which can download the metadata for all publications
associated with TreeBASE. 

``` {r   getmetadata }
    oai.md <- search_metadata() 
````

This returns an R list object, in which each element is an entry with
bibliographic information corresponding to a published study that has
deposited data in TreeBASE. From the length of this list we see that
there are currently `r prettyNum(length(oai.md)) ` published studies in the
database.

The `oai_metadata` function facilitates extracting the different meta-data fields. 
For instance, to obtain a list of all the dates of publication & names of the journals
(publishers) that have submitted data:


``` {r   journals }
    dates <- oai_metadata("date", oai.md) 
    pub <- oai_metadata("publisher", oai.md)
````

Many journals have only a few submissions, so we will classify any not in the 
top ten contributing journals as “Other”:


``` {r top_journals }
    topten <- sort(table(pub), decreasing=TRUE)[1:10]
    pub[!(pub %in% names(topten))] <- "Other"
````

We plot the distribution of publication years for
phylogenies deposited in TreeBASE, color coding by publisher in Fig
[fig:1]. 

``` {r dates, cache=FALSE, fig.cap="Histogram of publication dates by year, with the code required to generate the figure."}
    library(ggplot2)
    meta <- data.frame(pub = pub, dates = dates)
    ggplot(meta) + geom_bar(aes(dates, fill = pub))
````

Typically we are more interested in the metadata describing the phylogenies 
themselves rather than the publications in which they appeared, such as
the number of taxa in the tree, a quality score (if available), 
kind of tree (gene tree, species tree, or barcode tree) or whether the 
phylogeny represents a consensus tree from a distribution or just a single estimate.
The `cache_treebase` function is used to download all available phylogenies
from TreeBASE.  Here, we call the function with an optional argument that 
will return only the metadata just listed for all available phylogenies, 
which runs much more quickly. 


``` {r  tree_metadata_cache }
    phylo.md <- cache_treebase(only_metadata=TRUE)
````

We can summarize how these `r length(phylo.md)` trees 
break out by kind or type (The `xtable` command formats this as a
table) using the `phylo_metadata` function to extract the kind of tree
(gene/species/barcode) and type (single or consensus):


``` {r  kind, results='asis' }
 output <- table(phylo_metadata("kind", phylo.md), phylo_metadata("type", phylo.md))
 xtable::xtable(output)
````


For certain applications a user may wish to download all the available
phylogenies from TreeBASE. Using the `cache_treebase` function allows a
user to download a local copy of all trees. Because direct database
dumps are not available, this function has intentional delays to avoid
overtaxing the TreeBASE servers, and should be allowed a full day to
run.

``` {r buildcache, eval=FALSE }
    treebase <- cache_treebase()
```

Once run, the cache is saved compactly in memory where it can be easily
and quickly restored. For convenience, the `treebase` package comes with
a copy already cached, which can be loaded into memory.


``` {r loadcache}
    data(treebase)
````

Having access to both the metadata from the studies and from the
phylogenies in R lets us quickly combine these data sources in
interesting ways. For instance, with a few commands we can visualize how
the number of taxa on submitted phylogenies has increasing over time,
Figure [fig:2]. 

``` {r   taxagrowth, fig.cap="Combining the metadata available from publications and from phylogenies themselves, we can visualize the growth in taxa on published phylogenies. Note that the maximum size tree deposited each year is growing far faster than the average number."}
    phylo.id <- phylo_metadata("Study.id", phylo.md)
    oai.id <- oai_metadata("Study.id", oai.md)
    matches <- sapply(oai.id, match, phylo.id)
    Ntaxa <- phylo_metadata("ntaxa",  phylo.md[matches])
    Ntaxa[sapply(Ntaxa, is.null)] <- NA
    taxa <- data.frame(Ntaxa=as.numeric(unlist(Ntaxa)), meta)
    ggplot(taxa, aes(dates, Ntaxa)) + 
      geom_point(position = 'jitter', alpha = .8) + 
      scale_y_log10() + stat_smooth(aes(group = 1))
````

These tools can assist in data discovery by identifying potential datasets
that meet an arbitrary list of requirements.  For instance, if our analysis
requires consensus gene trees with 100 or more taxa appearing in the journals
_Nature_ or _Science_, we can grab them with a few successive filters:

```{r }
meta <- metadata_table()
meta[publisher %in% c("Nature", "Science") & ntaxa > 100 & kind == "Gene Tree",]
````



The promise of this exponential growth in the sizes of available
phylogenies, with some trees representing `r max(taxa$Ntaxa, na.rm=TRUE)`
taxa motivates the more and more ambitious inference methods being developed
which require large trees to have adequate signal 
[@boettiger2012; @fitzjohn2009; @beaulieu2012].


Reproducible research
====================


Reproducible research has become a topic of increasing concern in 
recent years, and facilitating access to data and using scripts that 
can replicate analyses can help lower barriers to the replication 
of statistical and computational results [@schwab2000; @gentleman2004; @peng2011b]. 
The `treebase` package facilitates this process, as we illustrate in 
a simple example.  

Consider the shifts in speciation rate identified by @derryberry2011
on a phylogeny of ovenbirds and treecreapers, which uses the methods 
provided in the R package  `laser` [@rabosky2006b].  We will seek to not
only replicate the results, but also compare them against methods presented
in @stadler2011 in the package `TreePar`, which permits speciation models 
that were not available to @derryberry2011 at the time of their study.

Obtaining the tree
------------------

By drawing on the rich data manipulation tools available in R 
which should be familiar to the large R phylogenetics community,
the ` treebase ` package allows us to construct richer queries
than are possible through TreeBASE alone. 

The fastest way to identify the data uses the digital object identifer (doi)
printed on the top of the article, 

``` {r doiquery}
results <- search_treebase("10.1111/j.1558-5646.2011.01374.x", "doi")
````

The search returns a list, since some studies contain many trees


``` {r doiqueryresults}
results 
````
In this case the single item in the list is the one we want:

``` {r firstone}
derryberry <- results[[1]]
````

Having successfully imported the phylogenetic tree corresponding to this study,
we can quickly replicate their analysis of which diversification process best
fits the data.  These steps can be easily implemented using the phylogenetics
packages we have just mentioned. As a comparison of speciation models is not
the focus of this paper, the complete code and explanation for these steps is
provided as an appendix.  Happily, this analysis confirms the author's original
conclusions, even when the more general model of @stadler2011 is considered.




Analyses across many phylogenies
================================

Large scale comparative analyses that seek to characterize evolutionary patterns
across many phylogenies increasingly common in phylogenetic methods 
[_e.g._ @mcpeek2007; @phillimore2008; @mcpeek2008; @quental2010; @davies2011a].  
Sometimes referred to by their authors as meta-analyses,
these approaches have focused on re-analyzing phylogenetic trees collected from
many different earlier publications.  
This is a more direct approach than the traditional concept of meta-analysis
where statistical results from earlier studies are weighted by their sample size
without actually repeating the statistical analyses of those papers.
Because the identical analysis can be repeated on the original data from each study,
this approach avoids some of the statistical challenges inherent in traditional 
meta-analyses summarizing results across heterogeneous approaches.  

To date, researchers have gone through heroic efforts simply to assemble these
data sets from the literature.  
As described in @mcpeek2007; (emphasis added)
> One data set was based on 163 published species-level molecular phylogenies
> of arthropods, chordates, and mollusks.  A PDF format file of each article 
> was obtained, and a digital snapshot of the figure was taken in Adobe Acrobat
> 7.0. This image was transferred to a PowerPoint (Microsoft) file and printed 
> on a laser printer. The phylogenies included in this study are listed in the 
> appendix. _All branch lengths were measured by hand from these  printed sheets
> using dial calipers._

Despite the recent appearance of digital tools that could now facilitate this
analysis without mechanical calipers, [_e.g._ treesnatcher, @laubach2007],
it is  easier and less error-prone to pull properly formatted phylogenies from
the database for this purpose. Moreover, as the available data increases with 
subsequent publications, updating earlier meta-analyses 
can become increasingly tedious. Using our package, a user can 
apply any analysis they have written for a single phylogeny across the
entire collection of suitable phylogenies in TreeBASE, which can help overcome 
such barriers to discovery and integration at this large scale.  Using the 
functions we introduce aboved, we provide in the Appendix a simple example 
that computes the gamma statistic of @pybus2000, which provides an measure of
when speciation patterns differ from the popular birth-death model.  We see
that many phylogenies fall outside the distribution of the statistic expected
under that model.  



Conclusion
==========

While we have focused on examples that require no additional data beyond
the phylogeny, a wide array of methods combine this data with
information about the traits, geography, or ecological community of the
taxa represented. In such cases we would need programmatic access to the
trait data as well as the phylogeny. The Dryad digital repository
([http://datadryad.org](http://datadryad.org)) is a popular host for
such data to support the data archiving requirements mentioned above.
While programmatic access to the repository is possible through the
`rdryad` package [@chamberlain2012], variation in data formatting
must first be overcome. Dedicated databases such as FishBASE
([http://fishbase.org](http://fishbase.org)) may be another alternative,
where morphological data can be queried for a list of species using the
`rfishbase` package [@rfishbase]. The development of similar
software for programmatic data access will rapidly extend the space and
scale of possible analyses.

The recent advent of mandatory data archiving in many of the major
journals publishing phylognetics-based research
[_e.g._ @fairbairn2010; @piwowar2011; @whitlock2010], is a
particularly promising development that should continue to fuel trend of
submissions seen in Fig. 1. Accompanied by faster and more
inexpensive techniques of NextGen sequencing, and the rapid expansion in
phylogenetic applications, we anticipate this rapid growth in available
phylogenies will continue. Faced with this flood of data, programmatic
access becomes not only increasingly powerful but an increasingly
necessary way to ensure we can still see the forest for all the trees.

Acknowledgements
================

CB wishes to thank S. Price for feedback on the manuscript, the TreeBASE
developer team for building and supporting the repository, and all
contributers to TreeBASE. CB is supported by a Computational Sciences
Graduate Fellowship from the Department of Energy under grant number
DE-FG02-97ER25308.

 
``` {r save, echo=FALSE }
    save(list=ls(), file="knit_treebase.rda")
````


# References


Appendix
========

Reproducible Research: A diversification rate analysis
------------------------------------------------------

Different diversification models make different assumptions 
about the rate of speciation, extinction, and how these rates may be changing
over time.  The authors consider eight different models, implemented in the 
laser package [@rabosky2006b]. This code fits each of the eight models to that
data:

``` {r   RR, tidy=FALSE  }
library(ape)
bt <- branching.times(derryberry)
library(laser)
models <- list(             yule = pureBirth(bt),  
                     birth_death = bd(bt),     
                     yule.2.rate = yule2rate(bt),
      linear.diversity.dependent = DDL(bt),    
 exponential.diversity.dependent = DDX(bt),
         varying.speciation_rate = fitSPVAR(bt),  
         varying.extinction_rate = fitEXVAR(bt),  
                    varying_both = fitBOTHVAR(bt)  
              )
````

Each of the model estimate includes an AIC score indicating the goodness of
fit, penalized by model complexity (lower scores indicate better fits)
We ask R to tell us which model has the lowest AIC score,

``` {r   extract_aic  }
aics <- sapply(models, `[[`, 'aic')
best_fit <- names(models[which.min(aics)])
```` 

and confirm the result presented in @derryberry2011; 
that the `r best_fit` model is the best fit to the data.  


In this fast-moving field, new methods often become available within the 
time-frame that another manuscript is submitted by its authors and the time
at which if first appears in print.  For instance, the more sophisticated
methods available in the more recent package, `TreePar`, introduced in
@stadler2011 were not used in this study.

``` {r   TreeSimError, echo=FALSE  }
# Locale settings to be safe
Sys.setlocale(locale="C") -> locale
rm(list="locale") # clean up
````

We load the new method and format the data as its manual instructs us

``` {r   treepar  }
require(TreePar)
x<-sort(getx(derryberry), decreasing=TRUE)
````

The best-fit model in the laser analysis was a yule (net diversification
rate) models with two separate rates.  We can ask ` TreePar ` to see if
a model with more rate shifts is favored over this single shift,
a question that was not possible to address using the tools provided in
`laser`. The previous analysis also considers a birth-death model that 
allowed speciation and extinction rates to be estimated separately, but 
did not allow for a shift in the rate of such a model.  Here we consider
models that have up to 4 different rates in Yule models, (The syntax in
`TreeParr` is slightly cumbersome, the [[2]] indicates where this command
happens to store the output models.)

``` {r   treepar_yule, include=FALSE  }
yule_models <- bd.shifts.optim(x, sampling = c(1,1,1,1), 
  grid = 5, start = 0, end = 60, yule = TRUE)[[2]]
````


``` {r   treepar_yule_show, eval=FALSE  }
yule_models <- bd.shifts.optim(x, sampling = c(1,1,1,1), 
  grid = 5, start = 0, end = 60, yule = TRUE)[[2]]
````

  
We also want to compare the performance of models which 
allow up to four shifts and also 
estimate extinction and speciation separately:

``` {r   treepar_birthdeath, include=FALSE  }
birth_death_models <- bd.shifts.optim(x, sampling = c(1,1,1,1), 
  grid = 5, start = 0, end = 60, yule = FALSE)[[2]]
````

``` {r   treepar_birthdeath_show, eval=FALSE  }
birth_death_models <- bd.shifts.optim(x, sampling = c(1,1,1,1), 
  grid = 5, start = 0, end = 60, yule = FALSE)[[2]]
````

The models output by these functions are ordered by increasing number of shifts.  
We can select the best-fitting model by AIC score,

``` {r   aic_yule  }
yule_aic <- sapply(yule_models, function(pars) 2 * (length(pars) - 1) + 2 * pars[1] )
birth_death_aic <- sapply(birth_death_models, function(pars) 2 * (length(pars) - 1) + 2 * pars[1] )
best_no_of_rates <- list(Yule = which.min(yule_aic), birth.death = which.min(birth_death_aic))
best_model <- which.min(c(min(yule_aic), min(birth_death_aic)))
````


which confirms that the `r names(best_no_of_rates[best_model])` `r best_no_of_rates[best_model][[1]]`-rate  
model is still the best choice based on AIC score.  Of the eight models 
in this second analysis, only three were in the original set considered 
(Yule 1-rate and 2-rate, and birth-death without a shift), so we could by
no means have been sure ahead of time that a birth death with a shift, or
a Yule model with a greater number of shifts, would not have fitted better.  

Tests across many phylogenies
-----------------------------

A standard test of this is the gamma statistic of @pybus2000
which tests the null hypothesis that the rates of speciation and extinction
are constant. The gamma statistic is normally distributed about 0 for a pure
birth or birth-death process, values larger than 0 indicate that internal 
nodes are closer to the tip then expected, while values smaller than 0 indicate
nodes farther from the tip then expected.  In this section, we collect all 
phylogenetic trees from TreeBASE and select those with branch length data that 
we can time-calibrate using tools available in R.  We can then calculate the 
distribution of this statistic for all available trees, and compare these 
results with those from the analyses mentioned above.  

The ` treebase ` package provides a compressed cache of the phylogenies
available in treebase.  This cache can be automatically updated with the
`cache_treebase` function,

``` {r   meta_harvest, eval=FALSE  }
treebase <- cache_treebase()
````

which may require a day or so to complete, 
and will save a file in the working directory named with treebase and
the date obtained.  For convenience, we can load the cached copy 
distributed with the ` treebase ` package:

``` {r   cachedcopy  }
data(treebase)
````

We will only be able to use those phylogenies that include branch length data.
We drop those that do not from the data set, 

``` {r   branchlengthfilter  }
      have <- have_branchlength(treebase)
      branchlengths <- treebase[have]

````

Like most comparative methods, this analysis will require ultrametric trees
(branch lengths proportional to time, rather than to mutational steps). 
As most of these phylogenies are calibrated with branch length proportional
to mutational step, we must time-calibrate each of them first.  

``` {r   timetree, cache=TRUE  }
timetree <- function(tree){
    try( chronoMPL(multi2di(tree)) )
}
tt <- drop_nontrees(sapply(branchlengths, timetree))
````
At this point we have `r length(tt)` time-calibrated phylogenies over which
we will apply the diversification rate analysis. 
Computing the gamma test statistic to identify devations from the 
constant-rates model takes a single line,

``` {r     }
gammas <- sapply(tt,  gammaStat)
````
and the resulting distribution of the statistic across available trees is shown Fig 3.

``` {r   gammadist, fig.cap="Distribution of the gamma statistic across phylogenies in TreeBASE. Strongly positive values are indicative of an increasing rate of evolution (excess of nodes near the tips), very negative values indicate an early burst of diversification (an excess of nodes near the root)."   }
qplot(gammas)
````


Because `treebase` makes it possible to perform this analysis entirely
by scripts using the latest treebase data, it is not only easier to
perform this analysis but also to update it to reflect the latest data.
Note that in this example it is not our objective to provide a thorough
analysis of diversification patterns and their possible interpretations,
as in @pybus2000; @mcpeek2007; @mcpeek2008; and @phillimore2008; but
merely to illustrate how the similar calculations to these can be easily
applied across the much larger datasets in the repository. This example
can be automatically updated to reflect the latest data in TreeBASE
simply by rerunning the code we present above.
